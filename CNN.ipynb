{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEXI5jkZNFzIzHoriOCMJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunyoungwoo/2024S-Ajou-ML-FP/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dwNwO1upk83"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as v2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임을 사용하여 커스텀 데이터셋 생성\n",
        "class BaseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.dataframe.iloc[idx, 0]  # 이미지 파일 경로\n",
        "        image = Image.open(image_path).convert('RGB')  # 이미지 열기\n",
        "        label = self.dataframe.iloc[idx, 1]  # 레이블\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "sG8ucEO4qJGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임 로드 및 데이터 전처리 파이프라인 정의\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
        "    transforms.ToTensor(),  # torch 텐서로 변환\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화\n",
        "    transforms.RandomRotation(degrees=90),  # 랜덤 회전\n",
        "    transforms.RandomHorizontalFlip(p=0.5)  # 랜덤 수평 뒤집기\n",
        "])"
      ],
      "metadata": {
        "id": "V9wFHDclqMEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임을 사용하여 데이터셋 생성\n",
        "train_dataset = BaseDataset(train_df, transform=train_transforms)\n",
        "val_dataset = BaseDataset(val_df, transform=train_transforms)\n",
        "test_dataset = BaseDataset(test_df, transform=train_transforms)"
      ],
      "metadata": {
        "id": "beUGhrPRqRNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더 생성\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "oDp7IOpIqTyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv8 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=512 * 7 * 7, out_features=4096)\n",
        "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
        "        self.fc3 = nn.Linear(in_features=4096, out_features=10)  # 예시로 10개의 클래스에 대한 출력을 가정합니다.\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm7 = nn.BatchNorm2d(512)\n",
        "        self.batchnorm8 = nn.BatchNorm2d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.batchnorm1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm4(self.conv4(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm5(self.conv5(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm6(self.conv6(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm7(self.conv7(x))))\n",
        "        x = self.pool(F.relu(self.batchnorm8(self.conv8(x))))\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "spapVgxZqcFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 및 CUDA 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ImprovedCNN().to(device)"
      ],
      "metadata": {
        "id": "B8ywIzUgqr4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 최적화 함수 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "jziMszFRqs3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 평가 함수 정의\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100. * correct / total\n",
        "    return train_loss, train_acc"
      ],
      "metadata": {
        "id": "DvbuWQusqZ_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    val_loss = running_loss / len(val_loader)\n",
        "    val_acc = 100. * correct / total\n",
        "    return val_loss, val_acc"
      ],
      "metadata": {
        "id": "t0SREEbrqvcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping 관련 변수 설정\n",
        "patience = 5  # 성능이 향상되지 않은 에포크를 얼마나 기다릴 것인지 지정\n",
        "counter = 0  # 성능이 향상되지 않은 에포크 카운터 초기화\n",
        "best_val_loss = np.inf  # 가장 낮은 검증 손실값을 저장할 변수 초기화"
      ],
      "metadata": {
        "id": "VfmA0nSmsEEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 검증 실행\n",
        "NUM_EPOCHS = 10\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # 검증 손실이 이전 최고 손실값보다 낮은 경우 모델 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        counter = 0  # 성능이 향상되었으므로 카운터 초기화\n",
        "    else:\n",
        "        counter += 1  # 성능이 향상되지 않았으므로 카운터 증가\n",
        "\n",
        "    # 카운터가 지정된 인내심(patience)을 초과하면 학습 종료\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch+1} as validation loss did not improve for {patience} epochs.\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "OulL9zy9qwgC",
        "outputId": "241f93cb-cade-44ee-afcf-58789f2aac93"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7fc91311e7c8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    }
  ]
}