{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq9ZM5fLdW8UV0VzF41hya",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunyoungwoo/2024S-Ajou-ML-FP/blob/main/temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab 환경에 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3NB2EuKy3LW",
        "outputId": "3f55febb-afef-4f40-b3ca-fe463df728c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 디렉토리 경로 설정\n",
        "training_directory = '/content/drive/MyDrive/Colab Notebooks/dataset/Training'\n",
        "validation_directory = '/content/drive/MyDrive/Colab Notebooks/dataset/Validation'\n",
        "\n",
        "# 이미지 및 라벨 폴더 경로 설정\n",
        "training_image_directory = os.path.join(training_directory, 'image')\n",
        "training_label_directory = os.path.join(training_directory, 'label')\n",
        "validation_image_directory = os.path.join(validation_directory, 'image')\n",
        "validation_label_directory = os.path.join(validation_directory, 'label')\n",
        "\n",
        "# 이미지 및 라벨 파일 이름 리스트 생성\n",
        "training_image_list = os.listdir(training_image_directory)\n",
        "training_label_list = os.listdir(training_label_directory)\n",
        "validation_image_list = os.listdir(validation_image_directory)\n",
        "validation_label_list = os.listdir(validation_label_directory)\n",
        "\n",
        "# validation 데이터셋을 validation과 test로 분리\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    validation_image_list, validation_label_list, test_size=0.5, random_state=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "fSOgF7W6vt0-",
        "outputId": "7fedd2be-cc2a-4a0a-b099-8fc1241a5d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/path_to_json_file.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3ae52fe08709>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# JSON 파일 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/path_to_json_file.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframe(image_dir, label_dir, image_list, label_list):\n",
        "    data = []\n",
        "    for image_file, label_file in zip(image_list, label_list):\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "        with open(label_path, 'r') as f:\n",
        "            label_data = json.load(f)\n",
        "\n",
        "        # 'image file name'과 'value6' 값 추출\n",
        "        value6 = label_data.get('value6', None)\n",
        "        data.append({'image_file_name': image_path, 'value6': value6})\n",
        "\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "u1h_627xP9sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame 생성\n",
        "training_df = create_dataframe(training_image_directory, training_label_directory, training_image_list, training_label_list)\n",
        "validation_df = create_dataframe(validation_image_directory, validation_label_directory, val_images, val_labels)\n",
        "test_df = create_dataframe(validation_image_directory, validation_label_directory, test_images, test_labels)"
      ],
      "metadata": {
        "id": "BzrH_reyi66T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임 확인\n",
        "print(\"Training DataFrame length:\", len(training_df))\n",
        "print(\"Validation DataFrame length:\", len(validation_df))\n",
        "print(\"Test DataFrame length:\", len(test_df))\n",
        "\n",
        "print(\"\\nTraining DataFrame class distribution:\")\n",
        "print(training_df['value6'].value_counts())\n",
        "\n",
        "print(\"\\nValidation DataFrame class distribution:\")\n",
        "print(validation_df['value6'].value_counts())\n",
        "\n",
        "print(\"\\nTest DataFrame class distribution:\")\n",
        "print(test_df['value6'].value_counts())"
      ],
      "metadata": {
        "id": "Ht3E_5MKi-H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 증강 설정\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "BgQx0X8SjCgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 증강 함수\n",
        "def augment_data(df, datagen, class_id, target_count):\n",
        "    class_df = df[df['value6'] == class_id]\n",
        "    augmented_images = []\n",
        "    for index, row in class_df.iterrows():\n",
        "        image_path = row['image_file_name']\n",
        "        image = plt.imread(image_path)\n",
        "        image = image.reshape((1,) + image.shape)\n",
        "        count = 0\n",
        "        for batch in datagen.flow(image, batch_size=1):\n",
        "            new_image_path = f\"{os.path.splitext(image_path)[0]}_aug_{count}.jpg\"\n",
        "            augmented_images.append({'image_file_name': new_image_path, 'value6': class_id})\n",
        "            count += 1\n",
        "            if count >= target_count:\n",
        "                break\n",
        "    return pd.DataFrame(augmented_images)"
      ],
      "metadata": {
        "id": "gmQc5ukNjC6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불균형 해결을 위한 데이터 증강\n",
        "max_class_count = max(training_df['value6'].value_counts())\n",
        "augmented_data = []\n",
        "for class_id in training_df['value6'].unique():\n",
        "    class_count = training_df['value6'].value_counts()[class_id]\n",
        "    if class_count < max_class_count:\n",
        "        augmented_df = augment_data(training_df, datagen, class_id, max_class_count - class_count)\n",
        "        augmented_data.append(augmented_df)\n",
        "if augmented_data:\n",
        "    augmented_df = pd.concat(augmented_data)\n",
        "    training_df = pd.concat([training_df, augmented_df]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Pp5eSJQwjIj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "training_df['value6'] = one_hot_encoder.fit_transform(training_df[['value6']]).toarray()\n",
        "validation_df['value6'] = one_hot_encoder.transform(validation_df[['value6']]).toarray()\n",
        "test_df['value6'] = one_hot_encoder.transform(test_df[['value6']]).toarray()"
      ],
      "metadata": {
        "id": "Hwzr0PhzjPnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임 확인\n",
        "print(\"\\nTraining DataFrame after augmentation and one-hot encoding:\")\n",
        "print(training_df.head())\n",
        "\n",
        "print(\"\\nValidation DataFrame after one-hot encoding:\")\n",
        "print(validation_df.head())\n",
        "\n",
        "print(\"\\nTest DataFrame after one-hot encoding:\")\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "id": "ifh1Bz-ejQ8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 데이터프레임 저장 경로\n",
        "save_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# training_df, validation_df, test_df 저장\n",
        "with open(save_path + 'training_df.pickle', 'wb') as f:\n",
        "    pickle.dump(training_df, f)\n",
        "\n",
        "with open(save_path + 'validation_df.pickle', 'wb') as f:\n",
        "    pickle.dump(validation_df, f)\n",
        "\n",
        "with open(save_path + 'test_df.pickle', 'wb') as f:\n",
        "    pickle.dump(test_df, f)"
      ],
      "metadata": {
        "id": "gbOMoO95khRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 저장된 데이터프레임 불러오기\n",
        "load_path = '/content/drive/MyDrive/'\n",
        "\n",
        "with open(load_path + 'training_df.pickle', 'rb') as f:\n",
        "    training_df = pickle.load(f)\n",
        "\n",
        "with open(load_path + 'validation_df.pickle', 'rb') as f:\n",
        "    validation_df = pickle.load(f)\n",
        "\n",
        "with open(load_path + 'test_df.pickle', 'rb') as f:\n",
        "    test_df = pickle.load(f)"
      ],
      "metadata": {
        "id": "c3fLPUY2kp7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}